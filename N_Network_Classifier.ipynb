{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_iris()\n",
    "df = pd.DataFrame(data.data,columns=data.feature_names)\n",
    "df['target'] = data.target\n",
    "var = [x for x in df.columns if x!='target']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[var].copy()\n",
    "y = df['target'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = MLPClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\IRVINPATLANRAMIREZ\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xt, Xv, yt, yv = train_test_split(X,y,train_size=0.7)\n",
    "modelo.fit(Xt,yt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9809523809523809\n",
      "0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_pred=modelo.predict(Xt),y_true=yt))\n",
    "print(accuracy_score(y_pred=modelo.predict(Xv),y_true=yv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = dict(learning_rate = ['constant', 'invscaling', 'adaptive'],\n",
    "activation = ['identity', 'logistic', 'tanh', 'relu'],\n",
    "hidden_layer_sizes =[(x,y,z,) for x in range(2,25,5)  for y in range(2,25,5)  for z in (2,25,5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi = make_pipeline(StandardScaler(),PCA(),MinMaxScaler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('standardscaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('pca',\n",
       "                 PCA(copy=True, iterated_power='auto', n_components=None,\n",
       "                     random_state=None, svd_solver='auto', tol=0.0,\n",
       "                     whiten=False)),\n",
       "                ('minmaxscaler',\n",
       "                 MinMaxScaler(copy=True, feature_range=(0, 1)))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = pd.DataFrame(pi.transform(X),columns=['p%d'%x for x in range(1,len(X.columns)+1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.375325e-02</td>\n",
       "      <td>0.586871</td>\n",
       "      <td>3.917258e-01</td>\n",
       "      <td>4.644888e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.139489e-01</td>\n",
       "      <td>0.370750</td>\n",
       "      <td>3.343383e-01</td>\n",
       "      <td>3.822951e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.739736e-02</td>\n",
       "      <td>0.432961</td>\n",
       "      <td>4.840092e-01</td>\n",
       "      <td>4.601009e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.805379e-02</td>\n",
       "      <td>0.385120</td>\n",
       "      <td>5.092873e-01</td>\n",
       "      <td>5.584480e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.318817e-02</td>\n",
       "      <td>0.618106</td>\n",
       "      <td>4.687295e-01</td>\n",
       "      <td>5.271371e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.148248e-01</td>\n",
       "      <td>0.775838</td>\n",
       "      <td>4.747580e-01</td>\n",
       "      <td>4.827961e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.428327e-02</td>\n",
       "      <td>0.505906</td>\n",
       "      <td>6.403680e-01</td>\n",
       "      <td>5.280262e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.898833e-02</td>\n",
       "      <td>0.538769</td>\n",
       "      <td>4.126674e-01</td>\n",
       "      <td>5.153451e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.225987e-02</td>\n",
       "      <td>0.288135</td>\n",
       "      <td>5.381610e-01</td>\n",
       "      <td>5.176878e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.696181e-02</td>\n",
       "      <td>0.409160</td>\n",
       "      <td>3.240546e-01</td>\n",
       "      <td>5.312828e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9.992286e-02</td>\n",
       "      <td>0.692419</td>\n",
       "      <td>3.160476e-01</td>\n",
       "      <td>4.722421e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7.365832e-02</td>\n",
       "      <td>0.521903</td>\n",
       "      <td>5.106127e-01</td>\n",
       "      <td>6.288496e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9.135417e-02</td>\n",
       "      <td>0.360537</td>\n",
       "      <td>3.363232e-01</td>\n",
       "      <td>4.871573e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.321168e-02</td>\n",
       "      <td>0.316939</td>\n",
       "      <td>5.573358e-01</td>\n",
       "      <td>5.097188e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9.459331e-02</td>\n",
       "      <td>0.845286</td>\n",
       "      <td>2.064184e-01</td>\n",
       "      <td>2.866666e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8.416217e-02</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.766682e-01</td>\n",
       "      <td>4.370012e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>9.313940e-02</td>\n",
       "      <td>0.774795</td>\n",
       "      <td>4.574121e-01</td>\n",
       "      <td>2.928326e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9.597228e-02</td>\n",
       "      <td>0.588521</td>\n",
       "      <td>4.365453e-01</td>\n",
       "      <td>3.926335e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.439223e-01</td>\n",
       "      <td>0.760079</td>\n",
       "      <td>2.593261e-01</td>\n",
       "      <td>4.259895e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>7.082544e-02</td>\n",
       "      <td>0.708178</td>\n",
       "      <td>5.314796e-01</td>\n",
       "      <td>5.290488e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.413338e-01</td>\n",
       "      <td>0.573544</td>\n",
       "      <td>2.341228e-01</td>\n",
       "      <td>4.782995e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>9.323387e-02</td>\n",
       "      <td>0.670029</td>\n",
       "      <td>5.460998e-01</td>\n",
       "      <td>4.275519e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3.330669e-16</td>\n",
       "      <td>0.582811</td>\n",
       "      <td>6.386012e-01</td>\n",
       "      <td>4.692009e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.570532e-01</td>\n",
       "      <td>0.513005</td>\n",
       "      <td>4.787951e-01</td>\n",
       "      <td>3.321124e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>8.992240e-02</td>\n",
       "      <td>0.522685</td>\n",
       "      <td>5.236222e-01</td>\n",
       "      <td>7.713223e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.351673e-01</td>\n",
       "      <td>0.379835</td>\n",
       "      <td>2.962068e-01</td>\n",
       "      <td>4.442700e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.188477e-01</td>\n",
       "      <td>0.542330</td>\n",
       "      <td>5.066428e-01</td>\n",
       "      <td>4.191252e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>9.955029e-02</td>\n",
       "      <td>0.595695</td>\n",
       "      <td>3.492579e-01</td>\n",
       "      <td>4.789729e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.043183e-01</td>\n",
       "      <td>0.555635</td>\n",
       "      <td>3.147221e-01</td>\n",
       "      <td>4.018405e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>8.366144e-02</td>\n",
       "      <td>0.433743</td>\n",
       "      <td>4.970186e-01</td>\n",
       "      <td>6.025735e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>7.908018e-01</td>\n",
       "      <td>0.667472</td>\n",
       "      <td>5.863259e-01</td>\n",
       "      <td>3.145868e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>6.166476e-01</td>\n",
       "      <td>0.389919</td>\n",
       "      <td>9.048359e-01</td>\n",
       "      <td>4.607488e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>9.321214e-01</td>\n",
       "      <td>0.574440</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>6.224411e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>6.750287e-01</td>\n",
       "      <td>0.406763</td>\n",
       "      <td>4.573669e-01</td>\n",
       "      <td>3.437702e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>7.354230e-01</td>\n",
       "      <td>0.686844</td>\n",
       "      <td>6.204951e-01</td>\n",
       "      <td>5.539527e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>7.770978e-01</td>\n",
       "      <td>0.685694</td>\n",
       "      <td>2.348249e-01</td>\n",
       "      <td>7.173157e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>6.490423e-01</td>\n",
       "      <td>0.437738</td>\n",
       "      <td>5.300341e-01</td>\n",
       "      <td>3.589276e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>6.237091e-01</td>\n",
       "      <td>0.509033</td>\n",
       "      <td>6.415735e-01</td>\n",
       "      <td>4.987083e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>7.498216e-01</td>\n",
       "      <td>0.461900</td>\n",
       "      <td>6.055755e-01</td>\n",
       "      <td>4.572749e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>7.621958e-01</td>\n",
       "      <td>0.602275</td>\n",
       "      <td>7.611443e-02</td>\n",
       "      <td>7.067617e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>8.562472e-01</td>\n",
       "      <td>0.545536</td>\n",
       "      <td>6.957488e-02</td>\n",
       "      <td>5.083717e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>8.347147e-01</td>\n",
       "      <td>0.988772</td>\n",
       "      <td>1.953745e-01</td>\n",
       "      <td>7.103696e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>7.620406e-01</td>\n",
       "      <td>0.463550</td>\n",
       "      <td>6.503949e-01</td>\n",
       "      <td>3.854195e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>6.390249e-01</td>\n",
       "      <td>0.442133</td>\n",
       "      <td>3.617807e-01</td>\n",
       "      <td>6.839595e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>6.535401e-01</td>\n",
       "      <td>0.345063</td>\n",
       "      <td>3.718540e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>9.158715e-01</td>\n",
       "      <td>0.657423</td>\n",
       "      <td>1.688380e-01</td>\n",
       "      <td>1.812127e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>7.149666e-01</td>\n",
       "      <td>0.697080</td>\n",
       "      <td>9.680339e-01</td>\n",
       "      <td>4.525645e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>6.771749e-01</td>\n",
       "      <td>0.576086</td>\n",
       "      <td>5.573784e-01</td>\n",
       "      <td>7.142745e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>6.079121e-01</td>\n",
       "      <td>0.500209</td>\n",
       "      <td>6.840414e-01</td>\n",
       "      <td>4.842242e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>7.602891e-01</td>\n",
       "      <td>0.623591</td>\n",
       "      <td>4.534783e-01</td>\n",
       "      <td>2.861834e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>7.870375e-01</td>\n",
       "      <td>0.611936</td>\n",
       "      <td>6.902184e-01</td>\n",
       "      <td>2.316127e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>7.684631e-01</td>\n",
       "      <td>0.626109</td>\n",
       "      <td>5.301078e-01</td>\n",
       "      <td>2.220446e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>6.462120e-01</td>\n",
       "      <td>0.366118</td>\n",
       "      <td>7.448813e-01</td>\n",
       "      <td>5.319308e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>7.912689e-01</td>\n",
       "      <td>0.659430</td>\n",
       "      <td>6.418033e-01</td>\n",
       "      <td>4.425754e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>7.842991e-01</td>\n",
       "      <td>0.693445</td>\n",
       "      <td>7.997729e-01</td>\n",
       "      <td>2.665312e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>7.633225e-01</td>\n",
       "      <td>0.569445</td>\n",
       "      <td>5.978538e-01</td>\n",
       "      <td>8.386308e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>7.130479e-01</td>\n",
       "      <td>0.329076</td>\n",
       "      <td>4.461243e-01</td>\n",
       "      <td>2.601227e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>7.059140e-01</td>\n",
       "      <td>0.547368</td>\n",
       "      <td>5.570042e-01</td>\n",
       "      <td>3.654428e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.815292e-01</td>\n",
       "      <td>0.686345</td>\n",
       "      <td>9.613459e-01</td>\n",
       "      <td>4.624449e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>6.138005e-01</td>\n",
       "      <td>0.492428</td>\n",
       "      <td>7.438553e-01</td>\n",
       "      <td>6.597037e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               p1        p2            p3            p4\n",
       "0    8.375325e-02  0.586871  3.917258e-01  4.644888e-01\n",
       "1    1.139489e-01  0.370750  3.343383e-01  3.822951e-01\n",
       "2    6.739736e-02  0.432961  4.840092e-01  4.601009e-01\n",
       "3    7.805379e-02  0.385120  5.092873e-01  5.584480e-01\n",
       "4    6.318817e-02  0.618106  4.687295e-01  5.271371e-01\n",
       "5    1.148248e-01  0.775838  4.747580e-01  4.827961e-01\n",
       "6    5.428327e-02  0.505906  6.403680e-01  5.280262e-01\n",
       "7    8.898833e-02  0.538769  4.126674e-01  5.153451e-01\n",
       "8    7.225987e-02  0.288135  5.381610e-01  5.176878e-01\n",
       "9    9.696181e-02  0.409160  3.240546e-01  5.312828e-01\n",
       "10   9.992286e-02  0.692419  3.160476e-01  4.722421e-01\n",
       "11   7.365832e-02  0.521903  5.106127e-01  6.288496e-01\n",
       "12   9.135417e-02  0.360537  3.363232e-01  4.871573e-01\n",
       "13   2.321168e-02  0.316939  5.573358e-01  5.097188e-01\n",
       "14   9.459331e-02  0.845286  2.064184e-01  2.866666e-01\n",
       "15   8.416217e-02  1.000000  4.766682e-01  4.370012e-01\n",
       "16   9.313940e-02  0.774795  4.574121e-01  2.928326e-01\n",
       "17   9.597228e-02  0.588521  4.365453e-01  3.926335e-01\n",
       "18   1.439223e-01  0.760079  2.593261e-01  4.259895e-01\n",
       "19   7.082544e-02  0.708178  5.314796e-01  5.290488e-01\n",
       "20   1.413338e-01  0.573544  2.341228e-01  4.782995e-01\n",
       "21   9.323387e-02  0.670029  5.460998e-01  4.275519e-01\n",
       "22   3.330669e-16  0.582811  6.386012e-01  4.692009e-01\n",
       "23   1.570532e-01  0.513005  4.787951e-01  3.321124e-01\n",
       "24   8.992240e-02  0.522685  5.236222e-01  7.713223e-01\n",
       "25   1.351673e-01  0.379835  2.962068e-01  4.442700e-01\n",
       "26   1.188477e-01  0.542330  5.066428e-01  4.191252e-01\n",
       "27   9.955029e-02  0.595695  3.492579e-01  4.789729e-01\n",
       "28   1.043183e-01  0.555635  3.147221e-01  4.018405e-01\n",
       "29   8.366144e-02  0.433743  4.970186e-01  6.025735e-01\n",
       "..            ...       ...           ...           ...\n",
       "120  7.908018e-01  0.667472  5.863259e-01  3.145868e-01\n",
       "121  6.166476e-01  0.389919  9.048359e-01  4.607488e-01\n",
       "122  9.321214e-01  0.574440  1.110223e-16  6.224411e-01\n",
       "123  6.750287e-01  0.406763  4.573669e-01  3.437702e-01\n",
       "124  7.354230e-01  0.686844  6.204951e-01  5.539527e-01\n",
       "125  7.770978e-01  0.685694  2.348249e-01  7.173157e-01\n",
       "126  6.490423e-01  0.437738  5.300341e-01  3.589276e-01\n",
       "127  6.237091e-01  0.509033  6.415735e-01  4.987083e-01\n",
       "128  7.498216e-01  0.461900  6.055755e-01  4.572749e-01\n",
       "129  7.621958e-01  0.602275  7.611443e-02  7.067617e-01\n",
       "130  8.562472e-01  0.545536  6.957488e-02  5.083717e-01\n",
       "131  8.347147e-01  0.988772  1.953745e-01  7.103696e-01\n",
       "132  7.620406e-01  0.463550  6.503949e-01  3.854195e-01\n",
       "133  6.390249e-01  0.442133  3.617807e-01  6.839595e-01\n",
       "134  6.535401e-01  0.345063  3.718540e-01  1.000000e+00\n",
       "135  9.158715e-01  0.657423  1.688380e-01  1.812127e-01\n",
       "136  7.149666e-01  0.697080  9.680339e-01  4.525645e-01\n",
       "137  6.771749e-01  0.576086  5.573784e-01  7.142745e-01\n",
       "138  6.079121e-01  0.500209  6.840414e-01  4.842242e-01\n",
       "139  7.602891e-01  0.623591  4.534783e-01  2.861834e-01\n",
       "140  7.870375e-01  0.611936  6.902184e-01  2.316127e-01\n",
       "141  7.684631e-01  0.626109  5.301078e-01  2.220446e-16\n",
       "142  6.462120e-01  0.366118  7.448813e-01  5.319308e-01\n",
       "143  7.912689e-01  0.659430  6.418033e-01  4.425754e-01\n",
       "144  7.842991e-01  0.693445  7.997729e-01  2.665312e-01\n",
       "145  7.633225e-01  0.569445  5.978538e-01  8.386308e-02\n",
       "146  7.130479e-01  0.329076  4.461243e-01  2.601227e-01\n",
       "147  7.059140e-01  0.547368  5.570042e-01  3.654428e-01\n",
       "148  6.815292e-01  0.686345  9.613459e-01  4.624449e-01\n",
       "149  6.138005e-01  0.492428  7.438553e-01  6.597037e-01\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.500000e+02</td>\n",
       "      <td>1.500000e+02</td>\n",
       "      <td>1.500000e+02</td>\n",
       "      <td>1.500000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.559287e-01</td>\n",
       "      <td>4.969841e-01</td>\n",
       "      <td>4.602809e-01</td>\n",
       "      <td>4.896856e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.816882e-01</td>\n",
       "      <td>1.796232e-01</td>\n",
       "      <td>2.063385e-01</td>\n",
       "      <td>1.505543e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.330669e-16</td>\n",
       "      <td>4.996004e-16</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>2.220446e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.103729e-01</td>\n",
       "      <td>3.849153e-01</td>\n",
       "      <td>3.212117e-01</td>\n",
       "      <td>3.949352e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.246729e-01</td>\n",
       "      <td>5.002614e-01</td>\n",
       "      <td>4.735739e-01</td>\n",
       "      <td>4.825672e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.766384e-01</td>\n",
       "      <td>6.082191e-01</td>\n",
       "      <td>5.646995e-01</td>\n",
       "      <td>5.675413e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 p1            p2            p3            p4\n",
       "count  1.500000e+02  1.500000e+02  1.500000e+02  1.500000e+02\n",
       "mean   4.559287e-01  4.969841e-01  4.602809e-01  4.896856e-01\n",
       "std    2.816882e-01  1.796232e-01  2.063385e-01  1.505543e-01\n",
       "min    3.330669e-16  4.996004e-16  1.110223e-16  2.220446e-16\n",
       "25%    1.103729e-01  3.849153e-01  3.212117e-01  3.949352e-01\n",
       "50%    5.246729e-01  5.002614e-01  4.735739e-01  4.825672e-01\n",
       "75%    6.766384e-01  6.082191e-01  5.646995e-01  5.675413e-01\n",
       "max    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xs.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt,Xv,yt,yv = train_test_split(Xs,y,train_size=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(param_grid=param,\n",
    "                    n_jobs=-1,\n",
    "                    cv=3,\n",
    "                    estimator=modelo,\n",
    "                    scoring='accuracy',\n",
    "                    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 900 candidates, totalling 2700 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   11.5s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   26.5s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 2442 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 2700 out of 2700 | elapsed:  4.2min finished\n",
      "C:\\Users\\IRVINPATLANRAMIREZ\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 15s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\IRVINPATLANRAMIREZ\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=MLPClassifier(activation='relu', alpha=0.0001,\n",
       "                                     batch_size='auto', beta_1=0.9,\n",
       "                                     beta_2=0.999, early_stopping=False,\n",
       "                                     epsilon=1e-08, hidden_layer_sizes=(100,),\n",
       "                                     learning_rate='constant',\n",
       "                                     learning_rate_init=0.001, max_iter=200,\n",
       "                                     momentum=0.9, n_iter_no_change=10,\n",
       "                                     nesterovs_momentum=True, power_t=0.5,\n",
       "                                     random_sta...\n",
       "                                                (2, 12, 5), (2, 17, 2),\n",
       "                                                (2, 17, 25), (2, 17, 5),\n",
       "                                                (2, 22, 2), (2, 22, 25),\n",
       "                                                (2, 22, 5), (7, 2, 2),\n",
       "                                                (7, 2, 25), (7, 2, 5),\n",
       "                                                (7, 7, 2), (7, 7, 25),\n",
       "                                                (7, 7, 5), (7, 12, 2),\n",
       "                                                (7, 12, 25), (7, 12, 5),\n",
       "                                                (7, 17, 2), (7, 17, 25),\n",
       "                                                (7, 17, 5), (7, 22, 2),\n",
       "                                                (7, 22, 25), (7, 22, 5), ...],\n",
       "                         'learning_rate': ['constant', 'invscaling',\n",
       "                                           'adaptive']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "grid.fit(Xs,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9666666666666667\n",
      "0.9833333333333333\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_pred=modelo.predict(Xt),y_true=yt))\n",
    "print(accuracy_score(y_pred=modelo.predict(Xv),y_true=yv))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
